{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-processed data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preprocessed_data = \"C:/Users/RLOCAL/Documents/dataMedTeam/datachallenge_jfr/pre_processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# nber_minutes = 5*60\n",
    "# timeout = time.time() + 60*nber_minutes\n",
    "\n",
    "# while True:\n",
    "#     test = 0\n",
    "#     if test == nber_minutes or time.time() > timeout:\n",
    "#         break\n",
    "#     test = test - 1\n",
    "\n",
    "# print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1479, 691200)\n",
      "Train label shape: (1479, 8)\n",
      "Test data shape: (40, 691200)\n",
      "Test label shape: (40, 8)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(path_to_preprocessed_data + \"train_data_wi_oversampling.npy\")\n",
    "train_labels = np.load(path_to_preprocessed_data + \"train_labels_wi_oversampling.npy\")\n",
    "\n",
    "test_data = np.load(path_to_preprocessed_data + \"test_data_wi_oversampling.npy\")\n",
    "test_labels = np.load(path_to_preprocessed_data + \"test_labels_wi_oversampling.npy\")\n",
    "\n",
    "print(\"Train data shape: {}\".format(train_data.shape))\n",
    "print(\"Train label shape: {}\".format(train_labels.shape))\n",
    "\n",
    "print(\"Test data shape: {}\".format(test_data.shape))\n",
    "print(\"Test label shape: {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: CNN\n",
    "\n",
    "Dealing with an image processing classication problem, a convolutional neural network (CNN) classifier can bring very promising results. Given the few number of data provided, one should use anti over-fitting techniques such as : cross-validation and dropout technique.\n",
    "\n",
    "The mathemical formula of the 2-layer CNN implemented is exposed below:\n",
    "\n",
    "$$\n",
    "y=\\textrm{softmax}(ReLU(x\\ast W_1+b_1)W_2+b_2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"C:/Users/RLOCAL/Documents/dataMedTeam/datachallenge_jfr/model/\"\n",
    "model_name = \"my_cnn_model_wi_oversampling\"\n",
    "\n",
    "assert not os.path.exists(path_to_model + model_name)\n",
    "\n",
    "if not os.path.exists(path_to_model + model_name):\n",
    "    os.makedirs(path_to_model + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define computational graph (CG)\n",
    "batch_size = 40         # batch size\n",
    "d = train_data.shape[1]  # data dimensionality\n",
    "nc = 8                  # number of classes\n",
    "\n",
    "# CG inputs\n",
    "xin = tf.placeholder(tf.float32,[batch_size,d], name = \"xin\"); #print('xin=',xin,xin.get_shape())\n",
    "y_label = tf.placeholder(tf.float32,[batch_size,nc], name = \"y_label\"); #print('y_label=',y_label,y_label.get_shape())\n",
    "d = tf.placeholder(tf.float32, name= \"d\");\n",
    "\n",
    "# Convolutional layer\n",
    "K = 5   # size of the patch\n",
    "F = 10  # number of filters\n",
    "ncl = K*K*F\n",
    "Wcl = tf.Variable(tf.truncated_normal([K,K,1,F], stddev=tf.sqrt(2./tf.to_float(ncl)) )); #print('Wcl=',Wcl.get_shape())\n",
    "bcl = tf.Variable(tf.zeros([F])); #print('bcl=',bcl.get_shape())\n",
    "x_2d = tf.reshape(xin, [-1,720,960,1]); #print('x_2d=',x_2d.get_shape())\n",
    "x = tf.nn.conv2d(x_2d, Wcl, strides=[1, 1, 1, 1], padding='SAME')\n",
    "x += bcl; #print('x2=',x.get_shape())\n",
    "\n",
    "# ReLU activation\n",
    "x = tf.nn.relu(x)\n",
    "\n",
    "# Dropout\n",
    "x = tf.nn.dropout(x, d)\n",
    "\n",
    "# Fully Connected layer\n",
    "nfc = 720*960*F\n",
    "x = tf.reshape(x, [batch_size,-1]); #print('x3=',x.get_shape())\n",
    "Wfc = tf.Variable(tf.truncated_normal([nfc,nc], stddev=tf.sqrt(6./tf.to_float(nfc+nc)) )); #print('Wfc=',Wfc.get_shape())\n",
    "bfc = tf.Variable(tf.zeros([nc])); #print('bfc=',bfc.get_shape())\n",
    "y = tf.matmul(x, Wfc); #print('y1=',y,y.get_shape())\n",
    "y += bfc; #print('y2=',y,y.get_shape())\n",
    "\n",
    "# Softmax\n",
    "y = tf.nn.softmax(y, name=\"op_to_restore\"); #print('y3=',y,y.get_shape())\n",
    "\n",
    "# Loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(y), 1))\n",
    "total_loss = cross_entropy\n",
    "\n",
    "# Optimization scheme\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.025).minimize(total_loss)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(total_loss)\n",
    "\n",
    "# Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_label,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\RLOCAL\\Anaconda3\\envs\\jfr\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "\n",
      "Iteration i= 0 , train accuracy= 0.125 , loss= 4.314842\n",
      "test accuracy= 0.55\n",
      "elapsed time= 11.44505763053894 s\n",
      "\n",
      "Iteration i= 25 , train accuracy= 0.375 , loss= 4.8089175\n",
      "test accuracy= 0.55\n",
      "elapsed time= 199.7757704257965 s\n",
      "\n",
      "Iteration i= 50 , train accuracy= 0.35 , loss= 4.4305625\n",
      "test accuracy= 0.3\n",
      "elapsed time= 384.4500787258148 s\n",
      "\n",
      "Iteration i= 75 , train accuracy= 0.575 , loss= 3.1714473\n",
      "test accuracy= 0.675\n",
      "elapsed time= 567.2900023460388 s\n",
      "\n",
      "Iteration i= 100 , train accuracy= 0.375 , loss= 2.6897457\n",
      "test accuracy= 0.375\n",
      "elapsed time= 749.8853580951691 s\n",
      "\n",
      "Iteration i= 125 , train accuracy= 0.425 , loss= 2.2012868\n",
      "test accuracy= 0.65\n",
      "elapsed time= 929.8044137954712 s\n",
      "\n",
      "Iteration i= 150 , train accuracy= 0.45 , loss= 2.4907663\n",
      "test accuracy= 0.45\n",
      "elapsed time= 1110.8596503734589 s\n",
      "\n",
      "Iteration i= 175 , train accuracy= 0.325 , loss= 2.5246706\n",
      "test accuracy= 0.4\n",
      "elapsed time= 1291.7580778598785 s\n",
      "\n",
      "Iteration i= 200 , train accuracy= 0.625 , loss= 2.1658592\n",
      "test accuracy= 0.5\n",
      "elapsed time= 1472.3967792987823 s\n",
      "\n",
      "Iteration i= 225 , train accuracy= 0.575 , loss= 2.062822\n",
      "test accuracy= 0.55\n",
      "elapsed time= 1653.039295911789 s\n",
      "\n",
      "Iteration i= 250 , train accuracy= 0.425 , loss= 2.173304\n",
      "test accuracy= 0.35\n",
      "elapsed time= 1833.5904347896576 s\n",
      "\n",
      "Iteration i= 275 , train accuracy= 0.325 , loss= 2.087036\n",
      "test accuracy= 0.475\n",
      "elapsed time= 2016.0533275604248 s\n",
      "\n",
      "Iteration i= 300 , train accuracy= 0.5 , loss= 2.0760522\n",
      "test accuracy= 0.625\n",
      "elapsed time= 2196.9838120937347 s\n",
      "\n",
      "Iteration i= 325 , train accuracy= 0.35 , loss= 1.9264128\n",
      "test accuracy= 0.825\n",
      "elapsed time= 2377.3807520866394 s\n",
      "\n",
      "Iteration i= 350 , train accuracy= 0.45 , loss= 1.9354385\n",
      "test accuracy= 0.475\n",
      "elapsed time= 2558.290388584137 s\n",
      "\n",
      "Iteration i= 375 , train accuracy= 0.5 , loss= 1.8325676\n",
      "test accuracy= 0.425\n",
      "elapsed time= 2742.6953971385956 s\n",
      "\n",
      "Iteration i= 400 , train accuracy= 0.65 , loss= 1.8466116\n",
      "test accuracy= 0.4\n",
      "elapsed time= 2922.259955406189 s\n",
      "\n",
      "Iteration i= 425 , train accuracy= 0.45 , loss= 1.8551699\n",
      "test accuracy= 0.6\n",
      "elapsed time= 3103.714392900467 s\n",
      "\n",
      "Iteration i= 450 , train accuracy= 0.525 , loss= 1.9087589\n",
      "test accuracy= 0.35\n",
      "elapsed time= 3283.3464477062225 s\n",
      "\n",
      "Iteration i= 475 , train accuracy= 0.425 , loss= 2.181156\n",
      "test accuracy= 0.475\n",
      "elapsed time= 3462.6030197143555 s\n",
      "\n",
      "Iteration i= 500 , train accuracy= 0.8 , loss= 1.7296066\n",
      "test accuracy= 0.675\n",
      "elapsed time= 3641.8077161312103 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/RLOCAL/Documents/dataMedTeam/datachallenge_jfr/model/my_cnn_model_wi_oversampling/my_cnn_model_wi_oversampling'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Computational Graph\n",
    "n = train_data.shape[0]\n",
    "indices = collections.deque()\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "start_time = time.time()\n",
    "for i in range(501):\n",
    "    \n",
    "    # Batch extraction\n",
    "    if len(indices) < batch_size:\n",
    "        indices.extend(np.random.permutation(n)) \n",
    "    idx = [indices.popleft() for i in range(batch_size)]\n",
    "    batch_x, batch_y = train_data[idx,:], train_labels[idx]\n",
    "    #print(batch_x.shape,batch_y.shape)\n",
    "    \n",
    "    # Run CG for variable training\n",
    "    _,acc_train,total_loss_o = sess.run([train_step,accuracy,total_loss], feed_dict={xin: batch_x, y_label: batch_y, d: 0.25})\n",
    "    \n",
    "    # Run CG for test set\n",
    "    if not i%25:\n",
    "        print('\\nIteration i=',i,', train accuracy=',acc_train,', loss=',total_loss_o)\n",
    "        acc_test = sess.run(accuracy, feed_dict={xin: test_data, y_label: test_labels, d: 1.0})\n",
    "        print('test accuracy=',acc_test)\n",
    "        print(\"elapsed time= {} s\".format(time.time() - start_time))\n",
    "\n",
    "saver.save(sess, path_to_model + model_name + \"/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
