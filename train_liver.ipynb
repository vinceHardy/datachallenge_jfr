{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import os\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-processed data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preprocessed_data = \"C:/Users/vince/Documents/DataChallengeJFR/liver/pre_processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (327, 691200)\n",
      "Train label shape: (327, 8)\n",
      "Test data shape: (40, 691200)\n",
      "Test label shape: (40, 8)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(path_to_preprocessed_data + \"train_data.npy\")\n",
    "train_labels = np.load(path_to_preprocessed_data + \"train_labels.npy\")\n",
    "\n",
    "test_data = np.load(path_to_preprocessed_data + \"test_data.npy\")\n",
    "test_labels = np.load(path_to_preprocessed_data + \"test_labels.npy\")\n",
    "\n",
    "print(\"Train data shape: {}\".format(train_data.shape))\n",
    "print(\"Train label shape: {}\".format(train_labels.shape))\n",
    "\n",
    "print(\"Test data shape: {}\".format(test_data.shape))\n",
    "print(\"Test label shape: {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: CNN\n",
    "\n",
    "Dealing with an image processing classication problem, a convolutional neural network (CNN) classifier can bring very promising results. Given the few number of data provided, one should use anti over-fitting techniques such as : cross-validation and dropout technique.\n",
    "\n",
    "The mathemical formula of the 2-layer CNN implemented is exposed below:\n",
    "\n",
    "$$\n",
    "y=\\textrm{softmax}(ReLU(x\\ast W_1+b_1)W_2+b_2)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"C:/Users/vince/Documents/DataChallengeJFR/liver/model/\"\n",
    "model_name = \"my_cnn_model\"\n",
    "\n",
    "assert not os.path.exists(path_to_model + model_name)\n",
    "\n",
    "if not os.path.exists(path_to_model + model_name):\n",
    "    os.makedirs(path_to_model + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define computational graph (CG)\n",
    "batch_size = 40         # batch size\n",
    "d = train_data.shape[1]  # data dimensionality\n",
    "nc = 8                  # number of classes\n",
    "\n",
    "# CG inputs\n",
    "xin = tf.placeholder(tf.float32,[batch_size,d], name = \"xin\"); #print('xin=',xin,xin.get_shape())\n",
    "y_label = tf.placeholder(tf.float32,[batch_size,nc], name = \"y_label\"); #print('y_label=',y_label,y_label.get_shape())\n",
    "d = tf.placeholder(tf.float32, name= \"d\");\n",
    "\n",
    "# Convolutional layer\n",
    "K = 5   # size of the patch\n",
    "F = 10  # number of filters\n",
    "ncl = K*K*F\n",
    "Wcl = tf.Variable(tf.truncated_normal([K,K,1,F], stddev=tf.sqrt(2./tf.to_float(ncl)) )); #print('Wcl=',Wcl.get_shape())\n",
    "bcl = tf.Variable(tf.zeros([F])); #print('bcl=',bcl.get_shape())\n",
    "x_2d = tf.reshape(xin, [-1,720,960,1]); #print('x_2d=',x_2d.get_shape())\n",
    "x = tf.nn.conv2d(x_2d, Wcl, strides=[1, 1, 1, 1], padding='SAME')\n",
    "x += bcl; #print('x2=',x.get_shape())\n",
    "\n",
    "# ReLU activation\n",
    "x = tf.nn.relu(x)\n",
    "\n",
    "# Dropout\n",
    "x = tf.nn.dropout(x, d)\n",
    "\n",
    "# Fully Connected layer\n",
    "nfc = 720*960*F\n",
    "x = tf.reshape(x, [batch_size,-1]); #print('x3=',x.get_shape())\n",
    "Wfc = tf.Variable(tf.truncated_normal([nfc,nc], stddev=tf.sqrt(6./tf.to_float(nfc+nc)) )); #print('Wfc=',Wfc.get_shape())\n",
    "bfc = tf.Variable(tf.zeros([nc])); #print('bfc=',bfc.get_shape())\n",
    "y = tf.matmul(x, Wfc); #print('y1=',y,y.get_shape())\n",
    "y += bfc; #print('y2=',y,y.get_shape())\n",
    "\n",
    "# Softmax\n",
    "y = tf.nn.softmax(y, name=\"op_to_restore\"); #print('y3=',y,y.get_shape())\n",
    "\n",
    "# Loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(y), 1))\n",
    "total_loss = cross_entropy\n",
    "\n",
    "# Optimization scheme\n",
    "#train_step = tf.train.GradientDescentOptimizer(0.025).minimize(total_loss)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(total_loss)\n",
    "\n",
    "# Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_label,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vince\\Anaconda3\\envs\\learning\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "\n",
      "Iteration i= 0 , train accuracy= 0.3 , loss= 3.1186175\n",
      "test accuracy= 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:/Users/vince/Documents/DataChallengeJFR/liver/model/my_cnn_model/my_cnn_model'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Computational Graph\n",
    "n = train_data.shape[0]\n",
    "indices = collections.deque()\n",
    "init = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(1):\n",
    "    \n",
    "    # Batch extraction\n",
    "    if len(indices) < batch_size:\n",
    "        indices.extend(np.random.permutation(n)) \n",
    "    idx = [indices.popleft() for i in range(batch_size)]\n",
    "    batch_x, batch_y = train_data[idx,:], train_labels[idx]\n",
    "    #print(batch_x.shape,batch_y.shape)\n",
    "    \n",
    "    # Run CG for variable training\n",
    "    _,acc_train,total_loss_o = sess.run([train_step,accuracy,total_loss], feed_dict={xin: batch_x, y_label: batch_y, d: 0.25})\n",
    "    \n",
    "    # Run CG for test set\n",
    "    if not i%1:\n",
    "        print('\\nIteration i=',i,', train accuracy=',acc_train,', loss=',total_loss_o)\n",
    "        acc_test = sess.run(accuracy, feed_dict={xin: test_data, y_label: test_labels, d: 1.0})\n",
    "        print('test accuracy=',acc_test)\n",
    "\n",
    "saver.save(sess, path_to_model + model_name + \"/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
