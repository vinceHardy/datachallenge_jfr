{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_preprocessed_data = \"C:/Users/vince/Documents/DataChallengeJFR/liver/pre_processed/\"\n",
    "dict_class = {\"Malin\":0, \"Lesion\":1, \"Kyste\":2,\"Angiome\":3, \"CHC\":4, \"Foie Homogene\":5, \"HNF\":6, \"Metastase\":7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (40, 691200)\n",
      "Test label shape: (40, 8)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.load(path_to_preprocessed_data + \"test_data.npy\")\n",
    "test_labels = np.load(path_to_preprocessed_data + \"test_labels.npy\")\n",
    "\n",
    "print(\"Test data shape: {}\".format(test_data.shape))\n",
    "print(\"Test label shape: {}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"C:/Users/vince/Documents/DataChallengeJFR/liver/model/\"\n",
    "model_name = \"my_cnn_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/vince/Documents/DataChallengeJFR/liver/model/my_cnn_model/my_cnn_model\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph(path_to_model + model_name + \"/\" + model_name + \".meta\")\n",
    "saver.restore(sess, tf.train.latest_checkpoint(path_to_model + model_name))\n",
    "\n",
    "# Now, let's access and create placeholders variables and create feed-dict to feed new data\n",
    "graph = tf.get_default_graph()\n",
    "xin = graph.get_tensor_by_name(\"xin:0\")\n",
    "y_label = graph.get_tensor_by_name(\"y_label:0\")\n",
    "d = graph.get_tensor_by_name(\"d:0\")\n",
    "\n",
    "#Now, access the op that you want to run\n",
    "y = graph.get_tensor_by_name(\"op_to_restore:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on test data & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_inference = \"C:/Users/vince/Documents/DataChallengeJFR/liver/inference/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob = sess.run(y, feed_dict={xin: test_data, y_label: test_labels, d: 1.0})\n",
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Malin    Lésion     Kyste   Angiome       CHC  Foie Homogène       HNF  \\\n",
      "id                                                                              \n",
      "0   0.022928  0.239743  0.011054  0.002790  0.002368       0.695763  0.002372   \n",
      "1   0.015702  0.197550  0.006955  0.001564  0.001382       0.759754  0.001383   \n",
      "2   0.014764  0.196419  0.006503  0.001369  0.001238       0.763694  0.001239   \n",
      "3   0.021174  0.226904  0.009417  0.002218  0.001977       0.715088  0.001977   \n",
      "4   0.016331  0.207452  0.007372  0.001586  0.001421       0.748062  0.001423   \n",
      "\n",
      "    Métastase  \n",
      "id             \n",
      "0    0.022981  \n",
      "1    0.015710  \n",
      "2    0.014774  \n",
      "3    0.021244  \n",
      "4    0.016353  \n",
      "    Malin  Lésion  Kyste  Angiome  CHC  Foie Homogène  HNF  Métastase\n",
      "id                                                                   \n",
      "0     0.0     1.0    1.0      0.0  0.0            0.0  0.0        0.0\n",
      "1     0.0     0.0    0.0      0.0  0.0            1.0  0.0        0.0\n",
      "2     0.0     0.0    0.0      0.0  0.0            1.0  0.0        0.0\n",
      "3     0.0     1.0    1.0      0.0  0.0            0.0  0.0        0.0\n",
      "4     0.0     0.0    0.0      0.0  0.0            1.0  0.0        0.0\n"
     ]
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(y_prob, columns=list(dict_class.keys()))\n",
    "df_pred.index.name = \"id\"\n",
    "print(df_pred.head())\n",
    "\n",
    "df_ref = pd.DataFrame(test_labels, columns=list(dict_class.keys()))\n",
    "df_ref.index.name = \"id\"\n",
    "print(df_ref.head())\n",
    "\n",
    "df_pred.to_csv(path_to_inference + \"prediction.csv\")\n",
    "df_ref.to_csv(path_to_inference + \"reference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "HNF\n",
      "Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "CHC\n",
      "0.4763253968253968\n"
     ]
    }
   ],
   "source": [
    "print(metrics.foie_metrics(path_to_inference + \"reference.csv\", path_to_inference + \"prediction.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
